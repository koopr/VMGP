{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89293541-b4be-4695-a744-4b5383a15539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81aeae7-6abe-48e6-b121-aa92f0f6cc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599, 1279) (599, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vaegs.model import *\n",
    "from vaegs.utils import *\n",
    "from vaegs.train import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data599 = np.loadtxt('./data/wheat599_X.pkl.csv', delimiter=',')\n",
    "data599 = data599[:,1:]\n",
    "type_1 = np.loadtxt('./data/wheat1.Y', delimiter=',',skiprows=1)\n",
    "type_2 = np.loadtxt('./data/wheat2.Y', delimiter=',',skiprows=1)\n",
    "type_3 = np.loadtxt('./data/wheat3.Y', delimiter=',',skiprows=1)\n",
    "type_4 = np.loadtxt('./data/wheat4.Y', delimiter=',',skiprows=1)\n",
    "type599 = np.stack((type_1,type_2,type_3,type_4)).T\n",
    "print(data599.shape,type599.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04381480-9dee-4608-b124-63854f50d3ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type599.shape[1]\n",
    "file_name='wheat599.csv'\n",
    "net = VMGP(data599.shape[1],out_dim=out_dim)\n",
    "batch_size = 32\n",
    "train_test_klcv(net,data599, type599,num_epochs=50,lr=0.0001, print_skip = 50, device = device, \n",
    "                batch_size=batch_size, file_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8720ad-6168-473b-9e8e-673973958db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_train_kl(net, train_data, device, file_name, num_epochs=10, lr=1e-5, batch_size=32, shuffle=True, num_workers=0, print_skip = 50, opt = 'adam'):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('pre training on', device)\n",
    "    net.to(device)\n",
    "    if opt == 'adam':\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    elif opt == 'sgd':\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.MSELoss()\n",
    "    # 训练vae\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('epoch:', epoch)\n",
    "        net.train()\n",
    "        el = 0\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        for batch_idx, (X, _) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            X = X.to(device)\n",
    "            out = net(X)\n",
    "            X_hat = out[1]\n",
    "            mu, logvar = out[2],out[3]\n",
    "            kl_loss = -0.5*torch.mean(logvar+1-mu**2-torch.exp(logvar))   \n",
    "            l = loss(X_hat, X) + kl_loss\n",
    "            el += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        if epoch==0 or (epoch+1) % print_skip ==0:\n",
    "            print('epoch %d loss:'%(epoch+1), el/(batch_idx+1))\n",
    "    save_model(net, 'saved_models/'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ff094-f392-4fc5-b806-7ff967f1e2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type2.shape[1]\n",
    "net = VaeMultiNet3(data2.shape[1],  out_dim=out_dim)\n",
    "all_data = MyDataSet(data2, type2)\n",
    "pre_train_kl(net, all_data, device, 'wheat599_kl_pre.h5', num_epochs=500, lr=0.0001, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff7ef5-b4e0-4e59-bdbd-6b6d5ab71661",
   "metadata": {},
   "source": [
    "试验设计有问题，没有每个fold重新加载模型，效果巨好是因为预测数据模型已经见过了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5583b-dd8c-44f7-b1b2-32f5dc4005d0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type2.shape[1]\n",
    "samples = [50,None]\n",
    "file_name='wheat599_kl.csv'\n",
    "# appendresult(['rsample-m'], file_name)\n",
    "for sample in samples:\n",
    "    net = load_model('saved_models/wheat599_kl_pre.h5', device)\n",
    "    batch_size = 32\n",
    "    print('sample ',sample, 'with ', batch_size)\n",
    "    train_test_klcv(net,data2, type2,num_epochs=50,lr=0.0001, print_skip = 50, device = device, batch_size=batch_size,\n",
    "                  sample_size=sample, file_name=file_name,init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4757a5d-1e02-4b2f-a7f2-52825409b8ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type2.shape[1]\n",
    "samples = [50,None]\n",
    "file_name='wheat599_kl.csv'\n",
    "# appendresult(['rsample-m'], file_name)\n",
    "for sample in samples:\n",
    "    net = load_model('saved_models/wheat599_kl_pre.h5', device)\n",
    "    batch_size = 32\n",
    "    print('sample ',sample, 'with ', batch_size)\n",
    "    train_test_klcv(net,data2, type2,num_epochs=50,lr=0.0001, print_skip = 50, device = device, batch_size=batch_size,\n",
    "                  sample_size=sample, file_name=file_name,init=False, net_name = 'wheat599_kl_pre.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ce46-9b05-4fdd-9e1e-847ea6424ce2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type2.shape[1]\n",
    "samples = [50,None]\n",
    "file_name='wheat599_kl.csv'\n",
    "# appendresult(['rsample-m'], file_name)\n",
    "for sample in samples:\n",
    "    net = load_model('saved_models/wheat599_kl_pre.h5', device)\n",
    "    batch_size = 32\n",
    "    print('sample ',sample, 'with ', batch_size)\n",
    "    train_test_klcv(net,data2, type2,num_epochs=10,lr=0.0001, print_skip = 50, device = device, batch_size=batch_size,\n",
    "                  sample_size=sample, file_name=file_name,init=False, net_name = 'wheat599_kl_pre.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299c12c-f92e-4f56-b4c9-8f63f18545d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = try_gpu(2)\n",
    "out_dim = type2.shape[1]\n",
    "samples = [50,None]\n",
    "file_name='wheat599_kl.csv'\n",
    "# appendresult(['rsample-m'], file_name)\n",
    "for sample in samples:\n",
    "    net = load_model('saved_models/wheat599_kl_pre.h5', device)\n",
    "    batch_size = 32\n",
    "    print('sample ',sample, 'with ', batch_size)\n",
    "    train_test_klcv(net,data2, type2,num_epochs=100,lr=0.0001, print_skip = 50, device = device, batch_size=batch_size,\n",
    "                  sample_size=sample, file_name=file_name,init=False, net_name = 'wheat599_kl_pre.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b08f92-1b59-44a8-a69e-b7ae54fd16bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAMIE",
   "language": "python",
   "name": "jamie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
